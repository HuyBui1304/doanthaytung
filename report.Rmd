---
title: ""
author: ""

output:
  pdf_document:
    latex_engine: xelatex
    toc: false            
    number_sections: true
    fig_caption: true
    fig_height: 5
    fig_width: 7
    highlight: tango
    keep_tex: true
    includes:
      before_body: bia.tex
  html_document: default

header-includes:
  - \usepackage{pdfpages}
  - \usepackage{fontspec}
  - \setmainfont{Times New Roman}
---

\newpage
\thispagestyle{empty}

\begin{center}
    \LARGE \textbf{LỜI CAM ĐOAN}
\end{center}
\vspace{1.5em}

Chúng tôi, **Bùi Minh Huy**, **Trần Lê Vân**, **Nguyễn Thị Thanh Tâm** xin cam đoan rằng:

  Tất cả thông tin và phân tích trình bày trong báo cáo này được thực hiện một cách chính xác và trung thực. Mọi dữ liệu, nhận định hoặc ý kiến được trích dẫn từ các nguồn khác đều đã được nêu rõ nguồn gốc và trích dẫn đúng quy định. Chúng tôi cam đoan rằng không có bất kỳ hành vi sao chép hoặc sử dụng thông tin không hợp pháp nào từ các nguồn khác. Bài báo cáo này là kết quả của công trình nghiên cứu độc lập của chúng tôi và chưa từng được công bố tại bất kỳ nơi nào khác. Chúng tôi cam đoan đã tuân thủ nghiêm ngặt các quy tắc và quy định của môn học, bao gồm việc tham khảo và áp dụng các công cụ nghiên cứu một cách hợp lệ. Nếu phát hiện có bất kỳ sự gian lận nào, chúng tôi xin hoàn toàn chịu trách nhiệm về nội dung bài báo cáo của mình. Chúng tôi hy vọng rằng bài báo cáo này sẽ cung cấp những thông tin hữu ích cho các nhà nghiên cứu, doanh nghiệp, góp phần vào việc hiểu rõ hơn về mạng xã hội ngày nay.
    
\vspace{3em}

\begin{flushright}
\begin{minipage}{0.5\textwidth}
\raggedleft
TP.\ Hồ Chí Minh, ngày 28 tháng 3 năm 2025

\vspace{1em}

\centering
\textbf{\LARGE Sinh viên}
\end{minipage}
\end{flushright}


\newpage
\thispagestyle{empty}
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

# Abstract



# Introduction

  Trong thời đại của điện toán di động và thiết bị thông minh, việc theo dõi và nhận dạng hoạt động con người (Human Activity Recognition - HAR) đã trở thành một lĩnh vực nghiên cứu đóng vai trò quan trọng trong nhiều ngành như trí tuệ nhân tạo, khoa học dữ liệu, y học và công nghệ cảm biến. HAR đóng vai trò cốt lõi trong các ứng dụng như giám sát sức khỏe, phát hiện té ngã, điều khiển nhà thông minh. Ngày nay, nhu cầu càng ngày gia tăng về các thiết bị công nghệ có thể hiểu hành vi con người dẫn đến việc phát triển các mô hình HAR là chính xác, hiệu quả và có khả năng triển khai thực tế là vô cùng cần thết. 
  
  Một trong những yếu tố chính thúc đẩy sự phát triển của HẢ là sự phổ biến của các thiết bị di động thông minh và đồng hồ thông minh, vốn đợc trang bị sẵn các cảm biến quán tính bao gồm gia tốc kế (accelerometer) và con quay hồi chuyển (gyroscope). Những cảm biến này cho phép thu thập dữ liệu về chuyển động của người sử dụng với độ chính xác cao, chi phí thấp và tính khả dụng cao trong đời sống hàng ngày. Nhờ vậy, hệ thống HAR có thể được lắp đặt mà không cần sử dụng các thiết bị đắt tiền hoặc lắp đặt phức tạp.
  
  Bên cạnh tiềm năng ứng dụng rộng rãi, việc xây dựng các mô hình HAR vẫn có nhiều khó khăn thách thức như dữ liệu cảm biến thường có số chiều lớn, có nhiều dữ liệu nhiễu và có tính biến động cao do phụ thuộc vào thói quen và hình thể của mỗi người. Bên cạnh đó, một số hoạt động có thể có mẫu tín hiệu tương tự nhau khiến cho các bài toán phân loại trở nên khó khăn hơn. Vì vậy, cần có một quy trình xử lý dữ liệu bài bản bao gồm các bước tiền xử lý dữ liệu, giảm chiều dữ liệu và huấn luyện mô hình học máy để có thể đặt được hiệu quả cao trong việc nhận dạng hoạt động con người.
  
  Trong nghiên cứu này, chúng em đã tiến hành khai thác bộ dữ liệu "**Human Activity Recognition with Smartphones** " do UCI Machine Learning Repository cung cấp, một bộ dữ liệu được sử dụng rộng raix trong cộng đồng nghiên cứu HAR. Chúng em đề xuất một quy trình học máy toàn diện bao gồm phân tích đặc trưng, giảm chiều dữ liệu bằng UMAP, PCA, TSNE và huấn luyện bằng các mô hình học máy như Random Forest, Decision Tree, Logistic Regression, Support Vectot Machine (SVM) để phân loại các hoạt động với mục tiêu là nâng cao độ chính xác và hiệu quả của mô hình. Những kết quả này sẽ cung cấp cái nhìn thực nghiệm rõ ràng cho các nhà nghiên cứu, đồng thời làm nền móng cho việc triển khai các hệ thống nhận dạng hoạt động trong thế giới thực.
  
# Dataset and Preprocessing (Dữ liệu và tiền xử lý)

Bộ dữ liệu **Human Activity Recognition with Smartphones** được thu thập từ 30 người tham gia (gọi là *subjects*) (15 nam và 15 nữ, độ tuổi từ 19 đến 48) thực hiện sáu hoạt động thường ngày như Đi bộ (Walking), đi lên cầu thang (Walking Upstairs), đi xuống cầu thang (WalkingDownstairs), ngồi (Sitting),đứng (Standing),nằm (Laying). Dữ liệu được ghi lại bằng một điện thoại thông minh (Samsung Galaxy S II)  đeo ở thắt lưng của người dùng. Các cảm biến gồm **accelerometer** và **gyroscope** được sử dụng để ghi lại chuyển động theo 3 trục X, Y, Z với tần suất 50Hz.

  Mỗi chuỗi tín hiệu được chia thành các **cửa sổ trượt** có độ dài 2.56 giây, tương ứng với 128 lần đo. Từ mỗi cửa sổ, các đặc trưng (features) đã được trích xuất từ **miền thời gian** và **miền tần số** để tạo ra một tập hợp dữ liệu có cấu trúc sẵn sàng cho mô hình học máy.

Các nhóm tín hiệu chính bao gồm:

- `tBodyAcc-XYZ`: Gia tốc cơ thể theo 3 trục trong miền thời gian  
- `tGravityAcc-XYZ`: Gia tốc do trọng lực  
- `tBodyGyro-XYZ`: Tốc độ quay từ con quay hồi chuyển  
- `tBodyAccJerk-XYZ`, `tBodyGyroJerk-XYZ`: Jerk - đo sự thay đổi đột ngột của chuyển động  
- `Mag`: Độ lớn vector gia tốc, được tính bằng chuẩn Euclidean:  
  \[
  \text{Mag} = \sqrt{X^2 + Y^2 + Z^2}
  \]
- `fBodyAcc-XYZ`, `fBodyGyro-XYZ`: Biến miền tần số được tạo từ FFT

Từ các tín hiệu trên, một loạt đặc trưng thống kê được tính toán như:

- `mean()`, `std()`, `mad()`, `max()`, `min()`
- `sma()`: Signal Magnitude Area
- `energy()`: Tổng bình phương chia số phần tử
- `entropy()`, `iqr()`, `arCoeff()`, `correlation()`
- `meanFreq()`, `skewness()`, `kurtosis()`, `bandsEnergy()`, `angle()`

  Toàn bộ bộ dữ liệu được chia thành hai phần: Tập huấn luyện (train.csv): bao gồm 7352 mẫu. Tập kiểm tra (test.csv): bao gồm 2947 mẫu. Mỗi mẫu tương ứng với một cửa sổ thời gian 2.56 giây, được biểu diễn bằng **561 đặc trưng đầu vào (features)**, 1mỗi mẫu còn bao gồm một mã định danh người thực hiện (subject) và một nhãn hoạt động (Activity), ác nhãn này được mã hóa từ 1 đến 6 tương ứng với: 
  
| Giá trị nhãn | Hoạt động             |
|--------------|------------------------|
| 1            | WALKING                |
| 2            | WALKING_UPSTAIRS       |
| 3            | WALKING_DOWNSTAIRS     |
| 4            | SITTING                |
| 5            | STANDING               |
| 6            | LAYING                 |
```{r}
# install.packages("showtext")
# install.packages("ggplot2")
```


```{r}
# train <-read.csv('/Users/huy/Documents/doanthaytung/archive/train.csv')
# train <-read.csv("D:/BT/clonegit/doanthaytung/archive/train.csv")
train <- read.csv('archive/train.csv')
# head(train)
dim(train)
```

```{r}
# test <-read.csv('/Users/huy/Documents/doanthaytung/archive/test.csv')
# test <-read.csv("D:/BT/clonegit/doanthaytung/archive/test.csv")
test <- read.csv("archive/test.csv")
# head(test)
dim(test)
```
xem các các type có trong data
```{r}
table(sapply(train, class))
```

in ra cột có dạng charactor
```{r}
names(train)[sapply(train, class) == "character"]
```

```{r}
unique(train$Activity)
```
chuyển thành factor
```{r}
train$Activity <- as.factor(train$Activity)
test$Activity <- as.factor(test$Activity)
```

```{r}
cat("Giá trị thiếu ở tập train:", sum(is.na(train)), "\n")
cat("Giá trị thiếu ở tập test:", sum(is.na(test)), "\n")
```


```{r}
cat("Số dòng bị trùng lặp trong tập train:", sum(duplicated(train)), "\n")
cat("Số dòng bị trùng lặp trong tập test :", sum(duplicated(test)), "\n")
```


```{r, fig.width=16, fig.height=8}
library(ggplot2)
library(showtext)
showtext_auto()

ggplot(train, aes(x = factor(subject), fill = Activity)) +
  geom_bar(position = "dodge", width = 0.7) +
  scale_fill_brewer(palette = "Set2") + 
  labs(
    title = "Số lượng mẫu dữ liệu theo người dùng và hoạt động",
    x = "Người dùng (Subject)",
    y = "Số lượng mẫu",
    fill = "Hoạt động"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  )
```
  

```{r}
library(ggplot2)

ggplot(train, aes(x = Activity, fill = Activity)) +
  geom_bar() +
  labs(
    title = "Số lượng mẫu theo từng hoạt động",
    x = "Hoạt động",
    y = "Số lượng mẫu"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
    plot.title = element_text(hjust = 0.5, face = "bold")
  ) +
  guides(fill = "none")
```
  Số lượng mẫu cho mỗi hoạt động dao động trong khoảng 1000 mẫu đến 1200 mẫu. Các hoạt động tĩnh như laying, sitting, standing có xu hướng chiếm tỷ lệ cao hơn một chút so với các hoạt động di chuyển như walking, walking_upstairs, walking_downstairs. Mức độ chênh lệch không qua lớn giữa các nhóm, là điểm thuận lợi cho các mô hình học máy tránh bị lệch nhãn và đảm bảo khả năng học đều giữa các lớp.  
```{r}
columns <- colnames(train)
columns <- gsub("\\.", "", columns)
colnames(train) <- columns
colnames(test) <- columns
```


```{r, fig.width=18, fig.height=8}
library(ggplot2)

ggplot(train, aes(x = tBodyAccMagmean, color = Activity)) +
  geom_density(size = 1.2) +
  scale_color_brewer(palette = "Set1") +
  scale_x_continuous(limits = c(-1.1, 1)) + 
  labs(
    title = "Phân bố tBodyAccMagmean theo hoạt động",
    x = "tBodyAccMagmean",
    y = "Mật độ"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```


```{r, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)

p1 <- train %>%
  filter(Activity %in% c("SITTING", "STANDING", "LAYING")) %>%
  ggplot(aes(x = tBodyAccMagmean, color = Activity)) +
  geom_density(size = 1.2) +
  labs(
    title = "Static Activities (closer view)",
    x = "tBodyAccMagmean",
    y = "Density"
  ) +
  xlim(-1.05, -0.1) +
  ylim(0, 35) +
  theme_minimal(base_size = 14)
p1
```

```{r}
p2 <- train %>%
  filter(Activity %in% c("WALKING", "WALKING_DOWNSTAIRS", "WALKING_UPSTAIRS")) %>%
  ggplot(aes(x = tBodyAccMagmean, color = Activity)) +
  geom_density(size = 1.2) +
  labs(
    title = "Dynamic Activities (closer view)",
    x = "tBodyAccMagmean",
    y = "Density"
  ) + xlim(-0.65, 1) +
  theme_minimal(base_size = 14)

p2

```


```{r}
library(ggplot2)

ggplot(train, aes(x = Activity, y = tBodyAccMagmean)) +
  geom_boxplot(
    outlier.shape = NA,
    fill = "skyblue",
    color = "darkgreen",
    width = 0.6
  ) +
  labs(
    title = "Phân bố giữa tBodyAccMagmean và Activity",
    y = "tBodyAccMagmean",
    x = "Activity"
  ) +
  coord_cartesian(ylim = c(-1.1, 1.2)) + 
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.title.y = element_text(margin = margin(r = 10))
  )
```

```{r}
library(ggplot2)

ggplot(train, aes(x = Activity, y = angleXgravityMean)) +
  geom_boxplot(
    fill = "lightblue",
    color = "darkblue",
    outlier.shape = NA,
    width = 0.6
  ) +
  labs(
    title = "Phân bố giữa angleXgravityMean và Activity",
    x = "Activity",
    y = "angleXgravityMean"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
    axis.text.x = element_text(angle = 40, hjust = 1, size = 11)
  )
```


```{r}
library(ggplot2)

ggplot(train, aes(x = Activity, y = angleYgravityMean)) +
  geom_boxplot(
    fill = "lightblue",
    color = "darkblue",
    outlier.shape = NA,
    width = 0.6
  ) +
  labs(
    title = "Phân bố giữa angleYgravityMean và Activity",
    x = "Activity",
    y = "angleYgravityMean"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
    axis.text.x = element_text(angle = 40, hjust = 1, size = 11)
  )

```


```{r}
subject_ids <- train$subject
activity_labels <- train$Activity
sensor_data <- train[, !(names(train) %in% c("Activity", "subject"))]
subject_ids_test <- test$subject
activity_labels_test <- test$Activity
sensor_data_test <- test[, !(names(test) %in% c("Activity", "subject"))]

is_outlier_iqr <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR_val <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR_val
  upper_bound <- Q3 + 1.5 * IQR_val
  x < lower_bound | x > upper_bound
}

outlier_matrix <- mapply(is_outlier_iqr, sensor_data)

total_outlier_values <- sum(outlier_matrix)
total_cells <- nrow(sensor_data) * ncol(sensor_data)
percent_outlier_cells <- round(total_outlier_values / total_cells * 100, 2)

cat("Tổng số giá trị outlier:", total_outlier_values, "/", total_cells, "\n")
cat("Tỷ lệ giá trị outlier:", percent_outlier_cells, "%\n")
```


```{r}
cap_outliers <- function(df, lower = 0.01, upper = 0.99) {
  for (col in names(df)) {
    q_low <- quantile(df[[col]], lower, na.rm = TRUE)
    q_high <- quantile(df[[col]], upper, na.rm = TRUE)
    df[[col]] <- pmin(pmax(df[[col]], q_low), q_high)
  }
  df
}

sensor_data_capped <- cap_outliers(sensor_data)
sensor_data_test_capped <- cap_outliers(sensor_data_test)

train_capped <- cbind(sensor_data_capped, subject = subject_ids, Activity = activity_labels)
test_capped <- cbind(sensor_data_test_capped, subject = subject_ids_test, Activity = activity_labels_test)

str(train_capped)
str(test_capped)
```





```{r, fig.width=16, fig.height=8}
library(umap)
library(ggplot2)
library(gridExtra)

perform_umap_grid <- function(X_data, y_data,
                              neighbors_list = c(5, 15, 30),
                              min_dist_list = c(0.001, 0.01, 0.1)) {
  plots <- list()
  index <- 1
  
  for (n in neighbors_list) {
    for (d in min_dist_list) {
      config <- umap.defaults
      config$n_neighbors <- n
      config$min_dist <- d
      config$n_components <- 2
      
      umap_result <- umap(X_data, config = config)
      df <- as.data.frame(umap_result$layout)
      colnames(df) <- c("x", "y")
      df$label <- y_data
      
      p <- ggplot(df, aes(x = x, y = y, color = label)) +
        geom_point(size = 0.6, alpha = 0.6) +
        scale_color_brewer(palette = "Set1") +
        theme_minimal(base_size = 10) +
        labs(title = paste("n =", n, ", dist =", d), x = NULL, y = NULL) +
        theme(legend.position = "none",
              plot.title = element_text(size = 10, hjust = 0.5))
      
      plots[[index]] <- p
      index <- index + 1
    }
  }
  
  do.call(grid.arrange, c(plots, ncol = length(min_dist_list)))
}

perform_umap_grid(
  X_data = sensor_data_capped,
  y_data = train$Activity,
  neighbors_list = c(5, 15, 30),
  min_dist_list = c(0.001, 0.01, 0.1)
)
```


```{r}
library(umap)
library(ggplot2)

config <- umap.defaults
config$n_neighbors <- 30
config$min_dist <- 0.1
config$n_components <- 2

umap_result <- umap(sensor_data_capped, config = config)

umap_df <- as.data.frame(umap_result$layout)
colnames(umap_df) <- c("UMAP_1", "UMAP_2")
umap_df$Activity <- train$Activity

ggplot(umap_df, aes(x = UMAP_1, y = UMAP_2, color = Activity)) +
  geom_point(size = 0.7, alpha = 0.6) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal(base_size = 14) +
  labs(
    title = "UMAP (n_neighbors = 30, min_dist = 0.01)",
    x = "UMAP 1", y = "UMAP 2"
  )
```



```{r}
X_train <- train_capped[, !(names(train_capped) %in% c("subject", "Activity"))]
y_train <- train_capped$Activity

X_test <- test_capped[, !(names(test_capped) %in% c("subject", "Activity"))]
y_test <- test_capped$Activity

dim(X_train)
length(y_train)

dim(X_test)
length(y_test)
```

```{r}
head(train)
```


```{r, warning=FALSE}
train_and_evaluate_model <- function(
  model_name,
  X_train, y_train, X_test, y_test,
  class_labels,
  tuneGrid = NULL,
  k_folds = 5
) {
  if (!require(caret)) install.packages("caret", quiet = TRUE)
  if (!require(ggplot2)) install.packages("ggplot2", quiet = TRUE)

  library(caret)
  library(ggplot2)
  
  y_train <- as.factor(y_train)
  y_test <- as.factor(y_test)
  
  ctrl <- trainControl(method = "cv", number = k_folds)
  
  set.seed(123)
  model_fit <- train(
    x = X_train,
    y = y_train,
    method = model_name,
    trControl = ctrl,
    tuneGrid = tuneGrid
  )
  
  y_pred <- predict(model_fit, X_test)
  
  # Accuracy
  accuracy <- mean(y_pred == y_test)
  cat("---------------------\n")
  cat("|      Accuracy      |\n")
  cat("---------------------\n")
  cat(sprintf("\n    %.4f\n\n", accuracy))
  
  # Confusion matrix
  cm <- table(Predicted = y_pred, Actual = y_test)
  cat("--------------------\n")
  cat("| Confusion Matrix |\n")
  cat("--------------------\n")
  print(cm)
  
  # Plot confusion matrix
  cm_df <- as.data.frame(cm)
  colnames(cm_df) <- c("Predicted", "Actual", "Freq")
  
  ggplot(data = cm_df, aes(x = Actual, y = Predicted, fill = Freq)) +
    geom_tile(color = "white") +
    geom_text(aes(label = Freq), color = "black", size = 5) +
    scale_fill_gradient(low = "white", high = "darkgreen") +
    labs(title = "Confusion Matrix", x = "True Label", y = "Predicted Label") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Classification report
  cat("-------------------------\n")
  cat("| Classification Report |\n")
  cat("-------------------------\n")
  print(confusionMatrix(y_pred, y_test)$byClass)
  
  cat('--------------------------\n')
  cat('|     Best Parameters     |\n')
  cat('--------------------------\n')
  print(model_fit$bestTune)
  
  cat('--------------------------\n')
  cat('|      Best Accuracy      |\n')
  cat('--------------------------\n')
  print(max(model_fit$results$Accuracy))
  
  return(list(
    model = model_fit,
    accuracy = accuracy,
    confusion_matrix = cm,
    prediction = y_pred
  ))
}
```

```{r}
grid_logistic <- expand.grid(
  alpha = c(0, 1),
  lambda = 1 / c(0.01, 0.1, 1, 10, 20, 30)
)

results_log <- train_and_evaluate_model(
  model_name = "glmnet",
  X_train = X_train, y_train = y_train,
  X_test = X_test, y_test = y_test,
  class_labels = labels,
  tuneGrid = grid_logistic,
  k_folds = 5
)
```


```{r}
grid_linear_svc <- expand.grid(C = c(0.125, 0.5, 1, 2, 8, 16))

results_svc <- train_and_evaluate_model(
  model_name = "svmLinear",
  X_train = X_train, y_train = y_train,
  X_test = X_test, y_test = y_test,
  class_labels = labels,
  tuneGrid = grid_linear_svc,
  k_folds = 5
)
```

```{r}
grid_dt <- expand.grid(maxdepth = seq(3, 9, by = 2))

results_dt <- train_and_evaluate_model(
  model_name = "rpart2",  
  X_train = X_train,
  y_train = y_train,
  X_test = X_test,
  y_test = y_test,
  class_labels = labels,
  tuneGrid = grid_dt,
  k_folds = 5
)

```


